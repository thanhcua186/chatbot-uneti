import requests
from bs4 import BeautifulSoup

def scrape_uneti():
    url = "https://uneti.edu.vn/category/thong-bao/"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")

    news = soup.select("h3.post-title a")  # Kiá»ƒm tra selector
    print(f"ğŸ” Tá»•ng sá»‘ bÃ i viáº¿t tÃ¬m tháº¥y: {len(news)}")  # THÃŠM DÃ’NG NÃ€Y

    contents = []
    for item in news[:5]:
        title = item.get_text(strip=True)
        link = item['href']
        print(f"ğŸ“„ Äang láº¥y: {title} - {link}")  # THÃŠM DÃ’NG NÃ€Y

        try:
            article = requests.get(link)
            article_soup = BeautifulSoup(article.text, "html.parser")
            body = article_soup.select("div.td-post-content p")
            content = "\n".join(p.get_text(strip=True) for p in body[:3])
            contents.append(f"ğŸ“° {title}\n{content}\n---")
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi láº¥y bÃ i {title}: {e}")

    # Náº¿u khÃ´ng cÃ³ gÃ¬ Ä‘Æ°á»£c scrape
    if not contents:
        print("âš ï¸ KhÃ´ng láº¥y Ä‘Æ°á»£c ná»™i dung nÃ o. CÃ³ thá»ƒ cáº¥u trÃºc HTML Ä‘Ã£ thay Ä‘á»•i.")
    else:
        with open("data/thongbao.txt", "w", encoding="utf-8") as f:
            f.write("\n\n".join(contents))
        print("âœ… ÄÃ£ cáº­p nháº­t dá»¯ liá»‡u tuyá»ƒn sinh má»›i nháº¥t.")
