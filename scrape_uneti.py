import os
import requests
from bs4 import BeautifulSoup

def scrape_uneti():
    url = "https://uneti.edu.vn/category/thong-bao/"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")

    news = soup.select("h3.post-title a")
    print(f"ğŸ” Tá»•ng sá»‘ bÃ i viáº¿t tÃ¬m tháº¥y: {len(news)}")

    contents = []
    for item in news[:5]:
        title = item.get_text(strip=True)
        link = item['href']
        print(f"ğŸ“„ Äang láº¥y: {title} - {link}")

        try:
            article = requests.get(link)
            article_soup = BeautifulSoup(article.text, "html.parser")
            body = article_soup.select("div.td-post-content p")
            content = "\n".join(p.get_text(strip=True) for p in body[:3])
            contents.append(f"ğŸ“° {title}\n{content}\n---")
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi láº¥y bÃ i {title}: {e}")

    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    output_dir = os.path.join(os.path.dirname(__file__), "data")
    os.makedirs(output_dir, exist_ok=True)

    # Ghi file ra Ä‘Ãºng vá»‹ trÃ­
    output_path = os.path.join(output_dir, "thongbao.txt")
    if not contents:
        print("âš ï¸ KhÃ´ng láº¥y Ä‘Æ°á»£c ná»™i dung nÃ o.")
    else:
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("\n\n".join(contents))
        print("âœ… ÄÃ£ ghi dá»¯ liá»‡u vÃ o:", output_path)
